# Speaker diarization and transcription

Speaker diarization and transcription are essential components of modern speech analytics systems, enabling the identification of who spoke when in multi-speaker audio recordings. This project presents a Speaker Diarization and Speaker-Aware Transcription System that automatically segments an audio file into speaker-homogeneous regions and generates accurate transcriptions for each identified speaker.

The proposed system first performs speaker diarization using a pretrained deep learning pipeline to detect speaker boundaries and assign unique speaker labels. Each segmented speaker audio is then passed to an automatic speech recognition (ASR) model to generate text transcriptions. By integrating diarization with transcription, the system produces speaker-attributed transcripts, clearly indicating which speaker uttered each segment. This combined approach improves readability and interpretability compared to traditional speech-to-text systems.

To ensure usability, the entire pipeline is implemented as an interactive Streamlit web application, allowing users to upload audio files, visualize speaker segments, and view the transcriptions in a structured format such as tables or timelines. Experimental results demonstrate effective speaker separation and accurate transcription for multi-speaker recordings. This project showcases the practical application of deep learningâ€“based speech processing techniques and can be extended to support real-time diarization, multilingual transcription, and speaker identification.
